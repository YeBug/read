机器学习：

监督学习
  1.回归问题：描述连续的问题
  2.分类问题：离散的问题
无监督学习
  聚类问题

目标：针对特定实际的问题建立强泛化能力的模型
避免过拟合与欠拟合问题
有监督学习中，预测误差的来源主要有两部分，分别为 bias  与 variance，模型的性能取决于 bias 与 variance 的 tradeoff
理解 bias 与 variance 有助于我们诊断模型的错误，避免 over-fitting 或者 under-fitting.
Bias：度量了学习算法的期望输出与真实结果的偏离程度, 刻画了算法的拟合能力，Bias 偏高表示预测函数与真实结果差异很大。
Variance：则代表“同样大小的不同的训练数据集训练出的模型”与“这些模型的期望输出值”之间的差异。训练集变化导致性能变化， Variance 偏高表示模型很不稳定。
Noise：刻画了当前任务任何算法所能达到的期望泛化误差的下界，即刻画了问题本身的难度。
regularization:使得模型曲线更平滑，但是随着权重的增加可能会伤害bias，导致测试集erro更大
Error=Bias^2+Variance+Noise
underfitting:erro 受bias影响大，训练集与模型差距大,需要redesign model
overfitting:erro 受variance影响大，测试集与模型差距大，需要increase data/regularization

评估模型泛化能力：划分训练集与测试集
划分方法：1.留出法  2.交叉验证法 3.自助法
p28
